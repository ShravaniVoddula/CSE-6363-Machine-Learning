{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "270b8289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b821dd",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc01c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Tree():\n",
    "  def __init__(self,criterion,max_depth,min_samples_split,min_samples_leaf,no_of_features=None):\n",
    "    self.criterion=criterion\n",
    "    self.max_depth=max_depth\n",
    "    self.min_samples_split=min_samples_split\n",
    "    self.min_samples_leaf=min_samples_leaf\n",
    "    self.parent_node=None\n",
    "    self.no_of_features=no_of_features\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  def fit(self, X, y):\n",
    "        self.no_of_features = X.shape[1] if not self.no_of_features else min(X.shape[1],self.no_of_features)\n",
    "        \n",
    "        self.parent_node = self.grow_a_tree(X, y)\n",
    "\n",
    "  def grow_a_tree(self, X, y, depth=0):\n",
    "        no_of_samples=X.shape[0]\n",
    "      \n",
    "        no_of_attributes=X.shape[1]\n",
    "        classes=np.unique(y)\n",
    "        no_of_classes=len(classes)\n",
    "        \n",
    "\n",
    "      \n",
    "       \n",
    "        if (depth>=self.max_depth or no_of_classes==1 or no_of_samples<self.min_samples_split):\n",
    "            count = Counter(y)\n",
    "            _fre_class = count.most_common(1)[0][0]\n",
    "            return Node(_val=_fre_class)\n",
    "\n",
    "        indexes = np.random.choice(no_of_attributes, self.no_of_features, replace=False)\n",
    "        if(self.criterion==\"entropy\"):\n",
    "          max_gain = -1\n",
    "          s_index, s_t = None, None\n",
    "          for i in indexes:\n",
    "            Feature_val = X[:, i]\n",
    "            unique_values_of_x = np.unique(Feature_val)\n",
    "\n",
    "            for j in unique_values_of_x:\n",
    "                G = self.gain(y, Feature_val, j)\n",
    "\n",
    "                if G > max_gain:\n",
    "                    max_gain = G\n",
    "                    s_index = i\n",
    "                    s_t = j\n",
    "        if(self.criterion==\"gini\"):\n",
    "          max_gini=-1\n",
    "          s_index, s_t = None, None\n",
    "          for i in indexes:\n",
    "            Feature_val = X[:, i]\n",
    "            unique_values_of_x = np.unique(Feature_val)\n",
    "\n",
    "            for j in unique_values_of_x:\n",
    "                G = self.gini(y, Feature_val, j)\n",
    "\n",
    "                if G > max_gini:\n",
    "                    max_gini = G\n",
    "                    s_index = i\n",
    "                    s_t = j\n",
    "          \n",
    "        l_split_indexes, r_split_indexes= self.split(X[:, s_index], s_t)\n",
    "        #print(len(l_split_indexes))\n",
    "        if (len(l_split_indexes)<=self.min_samples_leaf or len(r_split_indexes)<=self.min_samples_leaf):\n",
    "             hl = Counter(y)\n",
    "             _fre_class = hl.most_common(1)[0][0]\n",
    "             return Node(_val=_fre_class)\n",
    "\n",
    "        l_splits = self.grow_a_tree(X[l_split_indexes, :], y[l_split_indexes], depth+1)\n",
    "        r_splits = self.grow_a_tree(X[r_split_indexes, :], y[r_split_indexes], depth+1)\n",
    "        \n",
    "\n",
    "\n",
    "        return Node(s_index, s_t, l_splits, r_splits)\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "  def split(self, Feature_val, k):\n",
    "    \n",
    "        l_split_indexes = np.argwhere(Feature_val <= k).flatten()\n",
    "        r_split_indexes= np.argwhere(Feature_val > k).flatten()\n",
    "        return l_split_indexes, r_split_indexes\n",
    "  def gain(self, y, Feature_val, K):\n",
    "        E_of_P = self._E(y)\n",
    "        l_split_indexes, r_split_indexes= self.split(Feature_val, K)\n",
    "        if len(l_split_indexes) == 0 or len(r_split_indexes) == 0:\n",
    "            return 0\n",
    "        noOFSamples = len(y)\n",
    "        noOFSamplesOFLeft, noOFSamplesOFRight = len(l_split_indexes), len(r_split_indexes)\n",
    "        e_l, e_r = self._E(y[l_split_indexes]), self._E(y[r_split_indexes])\n",
    "        E_of_C = (noOFSamplesOFLeft/noOFSamples) * e_l + (noOFSamplesOFRight/noOFSamples) * e_r\n",
    "        return E_of_P - E_of_C\n",
    "  def gini(self,y, Feature_val, K):\n",
    "    G_of_P=self._G(y)\n",
    "    \n",
    "    l_split_indexes, r_split_indexes= self.split(Feature_val, K)\n",
    "    if len(l_split_indexes) == 0 or len(r_split_indexes) == 0:\n",
    "            return 0\n",
    "    noOFSamples = len(y)\n",
    "    noOFSamplesOFLeft, noOFSamplesOFRight = len(l_split_indexes), len(r_split_indexes)\n",
    "    g_l, g_r = self._G(y[l_split_indexes]), self._G(y[r_split_indexes])\n",
    "    G_of_C = (noOFSamplesOFLeft/noOFSamples) * g_l + (noOFSamplesOFRight/noOFSamples) * g_r\n",
    "    return (G_of_P-G_of_C)\n",
    "\n",
    "\n",
    "  def _E(self, y):\n",
    "        x = np.bincount(y)\n",
    "        x1 = x / len(y)\n",
    "        #for i in range(x1):\n",
    "          #if(i>0):\n",
    "            #y+=-(i * np.log(i) )\n",
    "        return -np.sum([i * np.log(i) for i in x1 if i>0])\n",
    "  def _G(self, y):\n",
    "        x = np.bincount(y)\n",
    "        x1 = x / len(y)\n",
    "        return 1-np.sum([i * i for i in x1 if i>0])\n",
    "\n",
    "  def T(self, x, y):\n",
    "        if y.leafNode ():\n",
    "            return y._val\n",
    "\n",
    "        if x[y. _attribute] <= y. _thres:\n",
    "            return self.T(x, y. _l)\n",
    "        return self.T(x, y. _r)\n",
    "\n",
    "  def predict(self, X):\n",
    "        return np.array([self.T(x, self.parent_node) for x in X])\n",
    "class Node:\n",
    "    def __init__(self, _attribute=None,  _thres=None,  _l=None,  _r=None,*,_val=None):\n",
    "        self._attribute = _attribute\n",
    "        self. _thres =  _thres\n",
    "        self. _l =  _l\n",
    "        self. _r =  _r\n",
    "        self._val = _val\n",
    "        \n",
    "    def leafNode(self):\n",
    "        if (self._val==None):\n",
    "          return False\n",
    "        else: return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2719ca",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "376bc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "\n",
    "\n",
    "class Random_Forest:\n",
    "    def __init__(self,no_of_trees,min_no_of_features,criterion,max_depth,min_samples_split,min_samples_leaf,no_of_features=None):\n",
    "      self.no_of_trees=no_of_trees\n",
    "      self.criterion=criterion\n",
    "      self.max_depth=max_depth\n",
    "      self.min_samples_split=min_samples_split\n",
    "      self.min_samples_leaf=min_samples_leaf\n",
    "      self.parent_node=None\n",
    "      self.no_of_features=no_of_features\n",
    "      self.min_no_of_features=min_no_of_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.N = []\n",
    "        for _ in range(self.no_of_trees):\n",
    "            R= Decision_Tree(self.criterion,self.max_depth,self.min_samples_split,self.min_samples_leaf,self.no_of_features)\n",
    "            no_of_samples1 = X.shape[0]\n",
    "            i = np.random.choice(no_of_samples1, no_of_samples1, replace=True)\n",
    "            X=X[i]\n",
    "            y=y[i]\n",
    "            no_of_features1=X.shape[1]\n",
    "            l = randint(self.min_no_of_features,no_of_features1)\n",
    "            j= np.random.choice(l,l, replace=False)\n",
    "            X=X[:,j]\n",
    "            \n",
    "            R.fit(X, y)\n",
    "            self.N.append(R)\n",
    "\n",
    "    \n",
    "\n",
    "    def fre(self, y):\n",
    "        k = Counter(y)\n",
    "        k1 = k.most_common(1)[0][0]\n",
    "        return k1\n",
    "\n",
    "    def predict(self, X):\n",
    "        out = np.array([R.predict(X) for R in self.N])\n",
    "        xw = np.swapaxes(out, 0, 1)\n",
    "        out= np.array([Counter(i).most_common(1)[0][0] for i in xw])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c08917",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b4fac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "  def __init__(self,weak_learner,num_learners,learning_rate):\n",
    "    self.weak_learner=weak_learner\n",
    "\n",
    "    self.num_learners=num_learners\n",
    "    self.learning_rate = learning_rate\n",
    "    self.trees=[]\n",
    "    #self.weak_learner=[]\n",
    "    self.errors1=[]\n",
    "    self.alpha1=[]\n",
    "  def fit(self,X,y):\n",
    "    no_of_samples=X.shape[0]\n",
    "    no_of_features=X.shape[1]\n",
    "    weights=(1/no_of_samples)*np.ones(no_of_samples)\n",
    "    self.weights=weights\n",
    "    tree=Decision_Tree(\"entropy\",1,2,2)\n",
    "    tree.fit(X,y)\n",
    "    out=tree.predict(X)\n",
    "    err=self.error(out,y,self.weights)\n",
    "    i=0\n",
    "    while(self.num_learners> i or err==0):\n",
    "      self.trees.append(tree)\n",
    "      tree=Decision_Tree(\"entropy\",1,2,2)\n",
    "      tree.fit(X,y)\n",
    "      out=tree.predict(X)\n",
    "      err=self.error(out,y,self.weights)\n",
    "      alp=self.alpha(err)\n",
    "      self.errors1.append(err)\n",
    "      self.alpha1.append(alp)\n",
    "      self.weights=self.updateWeight(self.weights,alp,out,y)\n",
    "      i=i+1\n",
    "  def error(self,out,y,wieghts):\n",
    "    err= (sum(wieghts * (np.not_equal(y, out)).astype(int)))/sum(wieghts)\n",
    "    \n",
    "    return err\n",
    "  def alpha(self,error):\n",
    "    return np.log((1-error)/(error))\n",
    "  def updateWeight(self,wieghts,alp,out,y):\n",
    "    return wieghts * np.exp(alp * (np.not_equal(y, out)).astype(int))\n",
    "  def predict(self,X):\n",
    "    g = pd.DataFrame(index = range(len(X)), columns = range(self.num_learners)) \n",
    "    for i in range(self.num_learners):\n",
    "            out_i = self.trees[i].predict(X) * self.alpha1[i]\n",
    "            g.iloc[:,i] = out_i\n",
    "\n",
    "       \n",
    "    out = (1 * np.sign(g.T.sum())).astype(int)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15022b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "actual_y=pd.read_csv('gender_submission.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Store our test passenger IDs for easy access\n",
    "PassengerId = test['PassengerId']\n",
    "original_train = train.copy()\n",
    "original_train = train.copy()\n",
    "full_data = [train, test]\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;\n",
    "# Feature selection: remove variables no longer containing relevant information\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "\n",
    "y_train = train['Survived']\n",
    "\n",
    "\n",
    "x_train = train.drop(['Survived'], axis=1).values \n",
    "drop_elements1 = ['PassengerId']\n",
    "actual_y= actual_y['Survived']\n",
    "y_train = y_train.to_numpy()\n",
    "actual_y =  actual_y.to_numpy()\n",
    "x_test = test.values\n",
    "#print(actual_y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbeec70a",
   "metadata": {},
   "source": [
    "# Decision tree with gini as criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec07e9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8397129186602871\n"
     ]
    }
   ],
   "source": [
    "model2=Decision_Tree(\"gini\",100,4,3)\n",
    "model2.fit(x_train,y_train)\n",
    "out1=model2.predict(x_test)\n",
    "accuracy1=accuracy_score(actual_y,out1)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e36b4b7f",
   "metadata": {},
   "source": [
    "# Decision tree with entropy as criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8c9f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "model2=Decision_Tree(\"entropy\",100,2,2)\n",
    "model2.fit(x_train,y_train)\n",
    "out2=model2.predict(x_test)\n",
    "accuracy2=accuracy_score(actual_y,out2)\n",
    "print(accuracy2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f82ccca5",
   "metadata": {},
   "source": [
    "# RandomForest with entropy as criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5d5a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45215311004784686\n"
     ]
    }
   ],
   "source": [
    "model3=Random_Forest(15,5,\"entropy\",10,2,2,4)\n",
    "model3.fit(x_train,y_train)\n",
    "out3=model3.predict(x_test)\n",
    "accuracy3=accuracy_score(actual_y,out3)\n",
    "print(accuracy3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5eeacac3",
   "metadata": {},
   "source": [
    "# RandomForest with gini as criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31fa92e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5980861244019139\n"
     ]
    }
   ],
   "source": [
    "model4=Random_Forest(15,5,\"gini\",9,2,2,4)\n",
    "model4.fit(x_train,y_train)\n",
    "out4=model4.predict(x_test)\n",
    "accuracy4=accuracy_score(actual_y,out4)\n",
    "print(accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d89ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937799043062201\n"
     ]
    }
   ],
   "source": [
    "weaklearner=Decision_Tree(\"entropy\",1,2,2)\n",
    "model5=AdaBoost(weaklearner,10,0.1)\n",
    "model5.fit(x_train,y_train)\n",
    "out5=model5.predict(x_test)\n",
    "accuracy5=accuracy_score(actual_y,out5)\n",
    "print(accuracy5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5341a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ACCURACY TABLE\n",
      "\n",
      "          DecisionTree         RandomForest          Boosting\n",
      "Gini     0.8397129186602871    0.45215311004784686   \n",
      "Entrpy   0.7727272727272727    0.5980861244019139    0.937799043062201\n"
     ]
    }
   ],
   "source": [
    "print(\" ACCURACY TABLE\")\n",
    "print()\n",
    "print(\"          DecisionTree         RandomForest          Boosting\")\n",
    "print(\"Gini    \",accuracy1,\"  \",accuracy3,\"  \")\n",
    "print(\"Entrpy  \",accuracy2,\"  \",accuracy4,\"  \",accuracy5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27972ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f452f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
